---
title: "Scientific Annotation: Using Graphs to Facilitate Interdisciplinary Science"
date: 2019-11-01T13:59:09-07:00
draft: true
tags: ['ODSC']
---

Simon Goring - university of wisconsin - madison , UBC

# Motivation 

big problems we face as a society -> wicked problems 
- large scale issues vary in terms of solutions, underlyind data sets 
- the lense you come at it from gives you a very different solution 
- people come from many different disciplines and this has many different perpsective 
- your lense defines the problem differently 

All thinking about the same problem but thinking about it differently 
- this could be us using similar data sets or even different data sets and use them in different ways 
- there are also shared data sets 

as much as we might annotate these data sets or add meta - data 
- the way we add meta data comes from how we are trying to approach the problem 
- adding metadata is not something that everyone does 

quality and management of meta data becomes so much more important 

* * * 
4Vs of big data 
- Volume, Veracity, Velocity and Variety 

in earth sciences they fall along the variety and veracity
- everyone does something slightly differently 
- scientists are not great at following standards 
- not positive the numbers we are getting mean what we think they mean 

not necessarily big from a size, like tera bytes 
- but very complex and we need strategies to handle this 
- we want to combine a lot of different data sets together 

databases are not static, they are part of research units, and lots of people are interacting with them and changing them 

We want to manage the data and make it avaliable to as many people as possible 
- people will use it in a variety of ways 

want to manage variety by implementing better standards for how people interact with them. 
* * * 

figuring out the alignment and how different data sets aling is really hard 

- this kind of work often falls to undergraduates 
- when they figure out alignments often happens many times 

causes repreducibility problems, problems with equity 

Discoverability is such a real problem -> how do you find 

data entropy -> people know the most about data when it is published 
- over time they forget information about their data 

* * * 

Solution for all of this --> anothation graphs 
- earthcube and throughput 

workshop to see what kind of resources people want to connect 
- people want to connect a lot of different resources 

w3c annotation data model 
- i have a data resource and the target is a publication or a github 
- agent connects the two 
- econde it with neo4j 

translate these annotations into neo4j cypher queries 

tons of data resources and github repos linked
- we have a github repo and it connects two different resources 


* * * 

how do we then build recommendation systems 
- if this is what you are looking for, what kind of resources should i get 
- focused on the end user 

can also help the data repository manager,
- how are people using our data 
- are people transforming it over and over again 
- should we change our api 
- can wee see common errors that people see 

- keywords connected in data repository 

- this better information helps provide so many insights 
- where are we missing data, where do we have a ton of data 

Lots of specific examples for his discipline 

## my thoughts 

- part of the reason big data is so bad, its not only about volume 
- Neo4j is fucking tight 

- in the hard sciences seems like more of a collobrative nature, people should not be so self conscious 



