---
title: "Mcmc_lecture"
date: 2019-11-06T09:11:41-08:00
draft: true
---

all of our information is in our prior and our likelihood 
- We combine that to get our posterior 

Once we have that there is only one thing we can do 
- Take the expectation 

We get the expectation by doing integrals
- But integrals can be really hard 

We need a way to do numerical approximation 

Brute force approach isn’t possible because it scales exponentially  in number of dimensions —> we want to only focus on the places in the parameter space that matter 

The mode works in high dimensions as the place where the most probability space is, but in higher dimensions that is not the case. The majority of the probability space actually ends up being far away from the mode. 

The typical set is what we call the place where the majority of the distribution lies 

A markov chain is a series of states generated by this probability distribution 
- Distribution over where you might jump to 
- You sample from it —> jump to a new state 
- A series of random states driven by this distribution 
- We want a Markov transition that takes us turn the typical set 

Convergence is can we find the typical set 
Mixing is then the exploration of the typical set 

We integrate of the typical set, to integrate over the entire distribution, we integrate over the Markov chain to integrate over the typical set 

MCMC is not necessarily always computational efficient 

In warm up we through initial samples away because initial points do not inform us 

You need the fuzzy caterpillar to have an accurate estimator 

Markov chains have a step size, you can only jump so far, you will jump past something that has structure smaller than the step size  

Mcmc is conditional on N going to infinity but were need something better than that for a reasonable amount of time 

If your trace gets stuck for a fair amount of time, then effective sample size is meaning less. We need something geometric ergodicity to hold 

We do convergence diagnostics by taking chains and comparing them to other chains or comparing them to themselves. This is a big limitations of MCMC, but its really all we can do 

Random walk metropolis: start at a point, propose a new point based on Gaussian noice, and then we accept or reject that point based on if it is higher density 

Random walk does not work at high than six or seven dimensions  

Hamilton Monte Carlo has us do long jumps, while staying in a region of high probability   
